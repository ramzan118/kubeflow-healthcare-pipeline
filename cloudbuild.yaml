options:
  logging: CLOUD_LOGGING_ONLY

steps:
# Step 1: Build Docker image
- name: 'gcr.io/cloud-builders/docker'
  args: ['build', '-t', 'gcr.io/$PROJECT_ID/kubeflow-healthcare-pipeline:latest', '.']

# Step 2: Get GKE credentials
- name: 'gcr.io/cloud-builders/gcloud'
  args: [
    'container', 'clusters', 'get-credentials',
    '$_CLUSTER_NAME', '--zone=$_ZONE', '--project=$PROJECT_ID'
  ]

# Step 3: DEBUG - List files and test imports
- name: 'gcr.io/$PROJECT_ID/kubeflow-healthcare-pipeline:latest'
  entrypoint: 'bash'
  args: 
    - '-c'
    - |
      echo "=== DEBUGGING ==="
      echo "Current directory: $(pwd)"
      echo "Files:"
      ls -la
      echo "Python version: $(python3 --version)"
      echo "Installed packages:"
      pip list
      echo "Testing component import:"
      python3 -c "from components.process_data import process_healthcare_data; print('Import successful!')"
      echo "=== END DEBUG ==="

# Step 4: Compile pipeline with error handling
- name: 'gcr.io/$PROJECT_ID/kubeflow-healthcare-pipeline:latest'
  entrypoint: 'python3'
  args: 
    - '-c'
    - |
      import traceback
      try:
          from pipeline import main
          main()
      except Exception as e:
          print(f"COMPILATION FAILED: {str(e)}")
          traceback.print_exc()
          exit(1)

# Step 5: Upload pipeline
- name: 'gcr.io/$PROJECT_ID/kubeflow-healthcare-pipeline:latest'
  entrypoint: 'kfp'
  args: [
    'pipeline', 'upload',
    '--pipeline-package', 'healthcare_ml_pipeline.yaml',
    '--pipeline-name', 'healthcare-data-ml-pipeline'
  ]

images: ['gcr.io/$PROJECT_ID/kubeflow-healthcare-pipeline:latest']

substitutions:
  _CLUSTER_NAME: kubeflow-healthcare-cluster
  _ZONE: us-central1-a
